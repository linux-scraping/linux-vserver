--- ipc/sem.c	2012-01-09 15:14:59.000000000 +0000
+++ ipc/sem.c	2016-10-25 21:03:26.000000000 +0000
@@ -314,14 +314,6 @@
		return retval;
	}

-	id = ipc_addid(&sem_ids(ns), &sma->sem_perm, ns->sc_semmni);
+	id = ipc_addid(&sem_ids(ns), &sma->sem_perm, ns->sc_semmni);
-	if (id < 0) {
+	if (id < 0) {
-		security_sem_free(sma);
+		security_sem_free(sma);
-		ipc_rcu_putref(sma);
+		ipc_rcu_putref(sma);
-		return id;
+		return id;
-	}
+	}
-	ns->used_sems += nsems;
+	ns->used_sems += nsems;
-
	sma->sem_base = (struct sem *) &sma[1];

	for (i = 0; i < nsems; i++)
@@ -332,6 +324,15 @@
	INIT_LIST_HEAD(&sma->list_id);
	sma->sem_nsems = nsems;
	sma->sem_ctime = get_seconds();
+
+
	sem_unlock(sma);

	return sma->sem_perm.id;
@@ -1606,16 +1607,27 @@
		rcu_read_lock();
		un = list_entry_rcu(ulp->list_proc.next,
				    struct sem_undo, list_proc);
-		if (&un->list_proc == &ulp->list_proc)
-			semid = -1;
-		 else
-			semid = un->semid;
+		if (&un->list_proc == &ulp->list_proc) {
+			/*
+			 * We must wait for freeary() before freeing this ulp,
+			 * in case we raced with last sem_undo. There is a small
+			 * possibility where we exit while freeary() didn't
+			 * finish unlocking sem_undo_list.
+			 */
+			spin_unlock_wait(&ulp->lock);
+			rcu_read_unlock();
+			break;
+		}
+		spin_lock(&ulp->lock);
+		semid = un->semid;
+		spin_unlock(&ulp->lock);
		rcu_read_unlock();

+		/* exit_sem raced with IPC_RMID, nothing to do */
		if (semid == -1)
-			break;
+			continue;

-		sma = sem_lock_check(tsk->nsproxy->ipc_ns, un->semid);
+		sma = sem_lock_check(tsk->nsproxy->ipc_ns, semid);

		/* exit_sem raced with IPC_RMID, nothing to do */
		if (IS_ERR(sma))
